{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzUADAuAnBjraZDiMdwBVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atta007/Speech-Recognizer/blob/main/speech_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdVUotk9k21V",
        "outputId": "0a715dda-7110-4e5a-9db7-e123f6bc30a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/hmm-speech-recognition/hmm-speech-recognition-0.1.zip\n",
            "To: /content/hmm-speech-recognition-0.1.zip\n",
            "\r  0% 0.00/857k [00:00<?, ?B/s]\r100% 857k/857k [00:00<00:00, 79.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/hmm-speech-recognition/hmm-speech-recognition-0.1.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/hmm-speech-recognition-0.1.zip"
      ],
      "metadata": {
        "id": "46bLnA6_lI3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxTw5UYlMQN",
        "outputId": "6d095b8d-afbe-439e-e5a7-557fdbecb5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.2.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (374 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 71 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 122 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 133 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 143 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 153 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 174 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 184 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 194 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 204 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 215 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 225 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 245 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 256 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 266 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 276 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 286 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 296 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 307 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 327 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 337 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 348 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 358 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 368 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 374 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from hmmlearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install winspeech\n",
        "\n",
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjpzFqMtlyaY",
        "outputId": "8a485b9c-b0da-49fc-cb0a-1c7901b8db0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting winspeech\n",
            "  Downloading winspeech-1.0.1-py2.py3-none-any.whl (6.9 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32 (from winspeech) (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pywin32\u001b[0m\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 152 kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8yzdeerl9c4",
        "outputId": "37e0b37d-5c17-45c2-ae4b-c880e7b98644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speech-recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2_yPTF_m37J",
        "outputId": "0e4106e4-b7e3-402e-e966-f0600aabfd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement speech-recognition (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for speech-recognition\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z57QghaRo5KZ",
        "outputId": "cba836e4-4401-421f-dd33-50ba3051e93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-py3-none-any.whl size=5888 sha256=1540aeb4285efae0c79447c106081542514f9fa71eb481e25c90b26d4326dd4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/0e/94/28cd6afa3cd5998a63eef99fe31777acd7d758f59cf24839eb\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from hmmlearn import hmm\n",
        "#from speech_features import mfcc\n",
        "import speech_recognition \n",
        "from python_speech_features import mfcc\n"
      ],
      "metadata": {
        "id": "RTRp6DRtlgnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class to train the HMM \n",
        "class ModelHMM(object):\n",
        "    def __init__(self, num_components=4, num_iter=1000):\n",
        "        self.n_components = num_components\n",
        "        self.n_iter = num_iter\n",
        "\n",
        "        self.cov_type = 'diag' \n",
        "        self.model_name = 'GaussianHMM' \n",
        "\n",
        "        self.models = []\n",
        "\n",
        "        self.model = hmm.GaussianHMM(n_components=self.n_components, \n",
        "                covariance_type=self.cov_type, n_iter=self.n_iter)\n",
        "\n",
        "    # 'training_data' is a 2D numpy array where each row is 13-dimensional\n",
        "    def train(self, training_data):\n",
        "        np.seterr(all='ignore')\n",
        "        cur_model = self.model.fit(training_data)\n",
        "        self.models.append(cur_model)\n",
        "\n",
        "    # Run the HMM model for inference on input data\n",
        "    def compute_score(self, input_data):\n",
        "        return self.model.score(input_data)\n"
      ],
      "metadata": {
        "id": "ZKliLinyvkJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to build a model for each word\n",
        "def build_models(input_folder):\n",
        "    # Initialize the variable to store all the models\n",
        "    speech_models = []\n",
        "\n",
        "    # Parse the input directory\n",
        "    for dirname in os.listdir(input_folder):\n",
        "        # Get the name of the subfolder \n",
        "        subfolder = os.path.join(input_folder, dirname)\n",
        "\n",
        "        if not os.path.isdir(subfolder): \n",
        "            continue\n",
        "\n",
        "        # Extract the label\n",
        "        label = subfolder[subfolder.rfind('/') + 1:]\n",
        "\n",
        "        # Initialize the variables\n",
        "        X = np.array([])\n",
        "\n",
        "        # Create a list of files to be used for training\n",
        "        # We will leave one file per folder for testing\n",
        "        training_files = [x for x in os.listdir(subfolder) if x.endswith('.wav')][:-1]\n",
        "\n",
        "        # Iterate through the training files and build the models\n",
        "        for filename in training_files: \n",
        "            # Extract the current filepath\n",
        "            filepath = os.path.join(subfolder, filename)\n",
        "\n",
        "            # Read the audio signal from the input file\n",
        "            sampling_freq, signal = wavfile.read(filepath)\n",
        "            \n",
        "            # Extract the MFCC features\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter('ignore')\n",
        "                features_mfcc = mfcc(signal, sampling_freq)\n",
        "\n",
        "            # Append to the variable X\n",
        "            if len(X) == 0:\n",
        "                X = features_mfcc\n",
        "            else:\n",
        "                X = np.append(X, features_mfcc, axis=0)\n",
        "            \n",
        "        # Create the HMM model\n",
        "        model = ModelHMM()\n",
        "\n",
        "        # Train the HMM\n",
        "        model.train(X)\n",
        "\n",
        "        # Save the model for the current word\n",
        "        speech_models.append((model, label))\n",
        "\n",
        "        # Reset the variable\n",
        "        model = None\n",
        "\n",
        "    return speech_models\n",
        "\n",
        "# Define a function to run tests on input files\n",
        "def run_tests(test_files):\n",
        "    # Classify input data\n",
        "    for test_file in test_files:\n",
        "        # Read input file\n",
        "        sampling_freq, signal = wavfile.read(test_file)\n",
        "\n",
        "        # Extract MFCC features\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter('ignore')\n",
        "            features_mfcc = mfcc(signal, sampling_freq)\n",
        "\n",
        "        # Define variables\n",
        "        max_score = -float('inf') \n",
        "        output_label = None \n",
        "\n",
        "        # Run the current feature vector through all the HMM\n",
        "        # models and pick the one with the highest score\n",
        "        for item in speech_models:\n",
        "            model, label = item\n",
        "            score = model.compute_score(features_mfcc)\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                predicted_label = label\n",
        "\n",
        "        # Print the predicted output \n",
        "        start_index = test_file.find('/') + 1\n",
        "        end_index = test_file.rfind('/')\n",
        "        original_label = test_file[start_index:end_index]\n",
        "        print('\\nOriginal: ', original_label) \n",
        "        print('Predicted:', predicted_label)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    #args = build_arg_parser().parse_args()\n",
        "    input_folder = '/content/hmm-speech-recognition-0.1/audio'\n",
        "\n",
        "    # Build an HMM model for each word\n",
        "    speech_models = build_models(input_folder)\n",
        "\n",
        "    # Test files -- the 15th file in each subfolder \n",
        "    test_files = []\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        for filename in (x for x in files if '15' in x):\n",
        "            filepath = os.path.join(root, filename)\n",
        "            test_files.append(filepath)\n",
        "\n",
        "    run_tests(test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzr2AkOBvqJV",
        "outputId": "812549b6-19e0-40f8-c5a8-ef1e21f2cb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/lime\n",
            "Predicted: lime\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/kiwi\n",
            "Predicted: kiwi\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/orange\n",
            "Predicted: orange\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/apple\n",
            "Predicted: apple\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/peach\n",
            "Predicted: peach\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/banana\n",
            "Predicted: banana\n",
            "\n",
            "Original:  content/hmm-speech-recognition-0.1/audio/pineapple\n",
            "Predicted: pineapple\n"
          ]
        }
      ]
    }
  ]
}